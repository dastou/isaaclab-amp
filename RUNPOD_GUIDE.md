# üöÄ Guide RunPod - D√©ploiement Isaac Lab AMP

**Date**: 2025-11-09
**GPU**: A100 (80GB)
**Objectif**: Tester la migration Isaac Lab sur RunPod

---

## üìã Ce que nous avons d√©couvert

### ‚úÖ RunPod est PARFAIT pour notre cas

1. **GPU A100 d√©j√† configur√©** ‚úÖ
   - Drivers NVIDIA pr√©-install√©s
   - CUDA Toolkit inclus
   - nvidia-docker automatiquement configur√©

2. **Templates PyTorch pr√™ts √† l'emploi** ‚úÖ
   - PyTorch 2.4 + CUDA 12.4 disponible
   - Python 3.10/3.11 pr√©-install√©
   - Pas de setup manuel n√©cessaire

3. **Isaac Lab supporte Docker** ‚úÖ
   - Image officielle : `nvcr.io/nvidia/isaac-lab:2.3.0`
   - Mode headless parfait pour serveur
   - Compatible A100

---

## üéØ Plan d'Action (3 √âtapes)

### **√âtape 1**: Pr√©parer le Pod RunPod (5 min)
### **√âtape 2**: Installer Isaac Lab via Docker (10-15 min)
### **√âtape 3**: Tester l'entra√Ænement AMP (5-10 min)

**Temps total estim√©**: 20-30 minutes

---

## üì¶ √âtape 1: Pr√©parer le Pod RunPod

### A. Cr√©er le Pod

1. **Connecte-toi sur RunPod** : https://www.runpod.io/

2. **S√©lectionne le GPU**:
   - GPU: **A100 (80GB)** ‚úÖ (tu l'as d√©j√†)
   - Type: Pod

3. **Choisis le Template**:
   - **Option A** (Recommand√©e): `RunPod PyTorch 2.4`
   - **Option B**: `RunPod PyTorch` (derni√®re version)
   - **Option C**: Template Docker custom (on cr√©era une image)

4. **Configure le Pod**:
   - **Container Disk**: 50GB minimum (Isaac Lab est ~10-15GB)
   - **Volume Disk** (optionnel): 20GB pour logs/checkpoints
   - **Expose Ports**: Pas n√©cessaire pour headless

5. **D√©marre le Pod** ‚Üí Attends qu'il soit "Running"

### B. Connecte-toi au Pod

**Option 1: Terminal Web RunPod** (Plus simple)
- Clique sur "Connect" ‚Üí "Start Web Terminal"
- Terminal s'ouvre dans le navigateur

**Option 2: SSH** (Plus pro)
```bash
# R√©cup√®re la commande SSH depuis RunPod dashboard
ssh root@<pod-ip> -p <port> -i ~/.ssh/id_ed25519
```

### C. V√©rifier l'Environnement

```bash
# 1. V√©rifier GPU
nvidia-smi

# Doit afficher:
# - Tesla A100-SXM4-80GB
# - CUDA Version: 12.x
# - Driver Version: 535.x+

# 2. V√©rifier Docker
docker --version
# Docker version 26.x ou plus

# 3. V√©rifier nvidia-docker
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi
# Doit afficher les infos GPU depuis le container
```

‚úÖ **Si tout fonctionne, passe √† l'√âtape 2**

---

## üê≥ √âtape 2: Installer Isaac Lab

### Option A: Docker Pull (Recommand√© - Plus rapide)

```bash
# 1. Pull l'image officielle Isaac Lab
docker pull nvcr.io/nvidia/isaac-lab:2.3.0

# Temps: ~5-10 min (d√©pend de la connexion)
# Taille: ~10-15 GB

# 2. Cr√©er un dossier pour le code
mkdir -p ~/isaac-lab-workspace
cd ~/isaac-lab-workspace

# 3. Uploader ton code (voir section Transfert Code ci-dessous)
```

### Option B: Build depuis Source (Plus long mais plus flexible)

```bash
# 1. Cloner Isaac Lab
cd ~
git clone https://github.com/isaac-sim/IsaacLab.git
cd IsaacLab

# 2. Build l'image Docker
./docker/container.py start

# Temps: ~15-20 min
```

---

## üì§ Transfert du Code vers RunPod

### M√©thode 1: Git (Recommand√©e)

**Sur ton PC Windows** (si pas d√©j√† fait):
```bash
cd C:\Users\HP\Desktop\DIC2\DeepLearning\projet_matiere_dl\IsaacGymEnvs

# Initialiser Git
git init
git add .
git commit -m "Migration Isaac Lab compl√®te"

# Push vers GitHub
git remote add origin https://github.com/<ton-username>/isaaclab-amp.git
git push -u origin main
```

**Sur RunPod**:
```bash
cd ~/isaac-lab-workspace
git clone https://github.com/<ton-username>/isaaclab-amp.git
cd isaaclab-amp
```

### M√©thode 2: Upload Direct RunPod

1. **Zipper le projet** sur Windows:
   - Clique droit sur `IsaacGymEnvs` ‚Üí "Compress to ZIP"

2. **Upload via RunPod**:
   - Dans le Web Terminal, clique sur "Upload" (ic√¥ne en haut)
   - S√©lectionne le fichier ZIP
   - D√©zippe: `unzip IsaacGymEnvs.zip`

### M√©thode 3: SCP (Si SSH configur√©)

```bash
# Depuis Windows (PowerShell)
scp -P <runpod-port> -r IsaacGymEnvs root@<runpod-ip>:~/
```

---

## üèÉ √âtape 3: Lancer Isaac Lab et Tester

### A. D√©marrer le Container Isaac Lab

```bash
cd ~/isaac-lab-workspace/isaaclab-amp  # ou ton dossier

# Lancer le container avec ton code mont√©
docker run --name isaac-lab-amp \
  --gpus all \
  -it \
  --rm \
  --network=host \
  -e "ACCEPT_EULA=Y" \
  -e "PRIVACY_CONSENT=Y" \
  -v $(pwd):/workspace \
  -v ~/isaac-lab-cache:/isaac-sim/kit/cache:rw \
  nvcr.io/nvidia/isaac-lab:2.3.0 \
  /bin/bash
```

**Explication des options**:
- `--gpus all` : Donne acc√®s au GPU A100
- `-v $(pwd):/workspace` : Monte ton code dans le container
- `-v ~/isaac-lab-cache:...` : Cache pour acc√©l√©rer les d√©marrages
- `--rm` : Supprime le container √† la sortie (propre)
- `--network=host` : R√©seau partag√© (optionnel)

### B. Dans le Container - Installer les D√©pendances

```bash
# Tu es maintenant DANS le container Isaac Lab

# 1. Aller dans le workspace
cd /workspace

# 2. Installer RL-Games
pip install rl-games

# 3. Installer d√©pendances suppl√©mentaires
pip install tensorboardX

# 4. V√©rifier les imports (Test rapide)
python -c "from isaaclab_envs.learning import AMPAgent; print('‚úÖ Imports OK!')"
```

### C. Lancer l'Entra√Ænement de Test

```bash
# Test court: 512 env, 10 iterations, headless
python isaaclab_envs/scripts/train.py \
    --task HumanoidAMP \
    --num_envs 512 \
    --headless \
    --max_iterations 10 \
    --seed 42
```

**Ce qui va se passer**:
1. Cr√©ation de 512 environnements humanoid
2. Chargement des donn√©es motion capture
3. Initialisation agent AMP
4. 10 it√©rations d'entra√Ænement
5. Sauvegarde checkpoint

**Dur√©e estim√©e**: 5-10 minutes

**Si √ßa marche**: üéâ **Migration r√©ussie !**

---

## üìä Monitoring pendant l'Entra√Ænement

### Depuis un autre Terminal RunPod

```bash
# Ouvrir un 2√®me terminal

# Surveiller GPU
watch -n 1 nvidia-smi

# Surveiller les logs du container
docker logs -f isaac-lab-amp
```

### M√©triques √† observer

- **GPU Utilization**: Devrait √™tre ~80-100%
- **Memory Used**: ~10-20 GB (sur 80 GB A100)
- **Power Draw**: ~300-400W
- **Temperature**: ~60-80¬∞C

---

## üêõ Troubleshooting

### Erreur: "No module named 'omni'"

**Cause**: Isaac Lab pas correctement install√© dans le container

**Solution**:
```bash
# Utilise l'image officielle exactement comme indiqu√©
docker pull nvcr.io/nvidia/isaac-lab:2.3.0
```

### Erreur: "CUDA out of memory"

**Cause**: Trop d'environnements pour le GPU

**Solution**:
```bash
# R√©duire num_envs
python isaaclab_envs/scripts/train.py --num_envs 256 --headless
```

### Erreur: "Failed to create simulation"

**Cause**: Mode headless pas activ√© correctement

**Solution**:
```bash
# V√©rifier que --headless est bien pr√©sent
# ET que DISPLAY n'est pas d√©fini
unset DISPLAY
python isaaclab_envs/scripts/train.py --headless ...
```

### Erreur: "Motion files not found"

**Cause**: Donn√©es motion capture pas transf√©r√©es

**Solution**:
```bash
# V√©rifier pr√©sence des fichiers
ls -lh /workspace/assets/amp/motions/

# Si vide, re-upload le dossier assets/
```

### Container trop lent au d√©marrage

**Cause**: Pas de cache

**Solution**:
```bash
# Cr√©er le dossier cache
mkdir -p ~/isaac-lab-cache

# Utiliser -v pour monter le cache (d√©j√† dans la commande docker run)
```

---

## ‚ö° Optimisations RunPod

### 1. Utiliser un Volume Persistant

```bash
# Cr√©er un volume sur RunPod (via dashboard)
# Taille: 50GB
# Type: Network Volume

# Monter dans le container
docker run ... -v /runpod-volume:/data ...
```

**Avantages**:
- Logs/checkpoints persistent entre red√©marrages
- Pas de perte de donn√©es

### 2. Augmenter le Batch Size

```bash
# Avec A100 80GB, tu peux augmenter
python isaaclab_envs/scripts/train.py \
    --num_envs 4096 \  # Au lieu de 512
    --headless
```

**Performance**: ~2-3x plus rapide

### 3. Multi-GPU (si pod avec plusieurs A100)

```bash
# V√©rifier nombre de GPUs
nvidia-smi --list-gpus

# Utiliser tous les GPUs
docker run --gpus all ...

# Dans train.py, RL-Games d√©tectera automatiquement
```

---

## üí∞ Estimation Co√ªts RunPod

### A100 80GB (Secure Cloud)
- **Prix**: ~$1.89/heure
- **Test (30 min)**: ~$0.95
- **Entra√Ænement court (2h)**: ~$3.80
- **Entra√Ænement complet (10h)**: ~$19

### A100 80GB (Community Cloud - Moins cher)
- **Prix**: ~$0.80-1.20/heure
- **Test (30 min)**: ~$0.40-0.60
- **Entra√Ænement court (2h)**: ~$1.60-2.40

**Recommandation**: Utilise Community Cloud pour les tests

---

## üìù Checklist Compl√®te

### Avant de Commencer
- [ ] Compte RunPod cr√©√©
- [ ] Cr√©dits ajout√©s (~$5-10 pour tests)
- [ ] Code upload√© (Git ou ZIP)
- [ ] GPU A100 s√©lectionn√©

### Setup
- [ ] Pod d√©marr√© et "Running"
- [ ] Terminal connect√©
- [ ] `nvidia-smi` fonctionne
- [ ] Docker install√© et fonctionnel

### Installation
- [ ] Image Isaac Lab pull√©e
- [ ] Code transf√©r√© dans ~/isaac-lab-workspace
- [ ] Container d√©marr√©
- [ ] RL-Games install√©
- [ ] Imports test√©s avec succ√®s

### Test
- [ ] Entra√Ænement court lanc√© (10 iterations)
- [ ] Pas d'erreurs
- [ ] Checkpoint sauvegard√©
- [ ] Logs affich√©s correctement

### Validation
- [ ] GPU utilis√© √† ~80-100%
- [ ] Discriminateur fonctionne
- [ ] R√©compenses calcul√©es
- [ ] ‚úÖ **MIGRATION VALID√âE !**

---

## üéâ Prochaines √âtapes apr√®s Validation

Si le test fonctionne:

1. **Entra√Ænement complet** (optionnel):
   ```bash
   python isaaclab_envs/scripts/train.py \
       --task HumanoidAMP \
       --num_envs 4096 \
       --headless \
       --max_iterations 5000
   ```

2. **Sauvegarder les r√©sultats**:
   ```bash
   # Depuis le container
   tar -czf results.tar.gz runs/ logs/

   # Depuis RunPod (autre terminal)
   docker cp isaac-lab-amp:/workspace/results.tar.gz ~/

   # Download via RunPod dashboard
   ```

3. **√âvaluation du mod√®le**:
   ```bash
   python isaaclab_envs/scripts/train.py \
       --task HumanoidAMP \
       --checkpoint runs/HumanoidAMP/model.pth \
       --play
   ```

---

## üìö Ressources Utiles

### Documentation
- [Isaac Lab Docker Guide](https://isaac-sim.github.io/IsaacLab/main/source/deployment/docker.html)
- [RunPod Documentation](https://docs.runpod.io/)
- [RL-Games GitHub](https://github.com/Denys88/rl_games)

### Support
- RunPod Discord: https://discord.gg/runpod
- Isaac Lab GitHub Issues: https://github.com/isaac-sim/IsaacLab/issues

### Notre Documentation
- `README.md` - Documentation principale
- `ETAT_FINAL_PROJET.md` - √âtat complet du projet
- `RESUME_MIGRATION.md` - R√©sum√© migration

---

## üéØ R√©sum√© des Commandes Cl√©s

```bash
# ========================================
# SETUP INITIAL (une seule fois)
# ========================================

# 1. Pull image Isaac Lab
docker pull nvcr.io/nvidia/isaac-lab:2.3.0

# 2. Cr√©er workspace et uploader code
mkdir -p ~/isaac-lab-workspace
cd ~/isaac-lab-workspace
git clone https://github.com/<ton-repo>.git
cd <ton-repo>

# ========================================
# LANCER LE CONTAINER
# ========================================

docker run --name isaac-lab-amp \
  --gpus all -it --rm --network=host \
  -e "ACCEPT_EULA=Y" -e "PRIVACY_CONSENT=Y" \
  -v $(pwd):/workspace \
  -v ~/isaac-lab-cache:/isaac-sim/kit/cache:rw \
  nvcr.io/nvidia/isaac-lab:2.3.0 /bin/bash

# ========================================
# DANS LE CONTAINER
# ========================================

# Installer d√©pendances
pip install rl-games tensorboardX

# Test imports
python -c "from isaaclab_envs.learning import AMPAgent; print('‚úÖ OK!')"

# Lancer entra√Ænement test
python isaaclab_envs/scripts/train.py \
    --task HumanoidAMP \
    --num_envs 512 \
    --headless \
    --max_iterations 10
```

---

**Derni√®re mise √† jour**: 2025-11-09
**Test√© sur**: RunPod A100 80GB
**Statut**: Pr√™t √† tester üöÄ
